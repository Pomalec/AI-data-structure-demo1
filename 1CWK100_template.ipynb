{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pomalec/AI-data-structure-demo1/blob/main/1CWK100_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-cGRSPUXYPh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99855d2e-b57e-4800-9f15-feca29b94d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change current working directory\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/')"
      ],
      "metadata": {
        "id": "BTttuhQbYXjb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check we can see the dataset\n",
        "os.path.isfile('pneumonia_raw.csv')"
      ],
      "metadata": {
        "id": "ht2KGrNLYcvl",
        "outputId": "d7577d88-147d-45a2-840c-c9761983624b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1"
      ],
      "metadata": {
        "id": "skMLQWdjvkHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic structure\n",
        "\n",
        "Please use the structure below as your starting point. Once you are up and running then you are free to adjust it, but try to stick to the following basic approach: i) divide your investigation up into smaller code cells; ii) have text cells above each code cell briefly describing what is happening in the code, along with any relevant findings it produces.\n",
        "\n",
        "Relatively quickly, you should be able to reuse some code from the labs to prepare the assignment dataset and evaluate at least one model with a basic holdout recipe. This would get you a pass. Ask for help if you're struggling, and read the later sections once you're ready to start aiming for higher marks. Good luck!"
      ],
      "metadata": {
        "id": "aJEvS40MaQyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset preparation\n",
        "Example text: The following code prepares the data using a simple 60/40 holdout approach with shuffling."
      ],
      "metadata": {
        "id": "W1VxpAxE_k59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data preparation steps\n",
        "\n",
        "# Importing the packages we use\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loading all the observations\n",
        "observations = pd.read_csv('pneumonia_raw.csv')\n",
        "print(observations.head())\n",
        "\n",
        "# The column we are trying to predict\n",
        "target_feature = 'Pneumonia'\n",
        "\n",
        "# Separate the examples (features) from the labels (target feature)\n",
        "examples = observations.drop(columns=target_feature).to_numpy()\n",
        "labels = observations[target_feature].to_numpy()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_examples, test_examples, train_labels, test_labels = train_test_split(\n",
        "    examples,\n",
        "    labels,\n",
        "    test_size=0.4,\n",
        "    random_state=99,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Initialize a Decision Tree model\n",
        "model = DecisionTreeClassifier(random_state=99)\n",
        "\n",
        "# Train the model on the training data\n",
        "model.fit(train_examples, train_labels)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_examples)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy * 100, 1), \"%)\")"
      ],
      "metadata": {
        "id": "Rhr657wg_xfy",
        "outputId": "ff50a5c7-f953-4754-dd75-e6221f78b6ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Patient_ID  Patient_Age  Male  Xray_Brightness  Xray_Contrast  \\\n",
            "0  6664019195           60   1.0              0.7            0.2   \n",
            "1  4433763263           18   1.0              1.3            0.7   \n",
            "2  4622245411           43   1.0              1.3            0.6   \n",
            "3  2777404684           38   1.0              1.0            0.3   \n",
            "4  3339776374           23   1.0              1.1            0.5   \n",
            "\n",
            "   Silhouette_Sign  Max_Consolidation_Width  Max_Consolidation_Height  \\\n",
            "0              174                       32                        14   \n",
            "1              316                       10                        21   \n",
            "2              155                       15                        20   \n",
            "3              216                       21                        24   \n",
            "4              191                       37                        41   \n",
            "\n",
            "   Cavity_Presence  Fluid_Level  Air_Bronchograms Pneumonia  \n",
            "0              7.8          4.2               1.1        no  \n",
            "1              6.0          2.1               0.5        no  \n",
            "2              8.0          4.0               1.0        no  \n",
            "3              7.3          4.4               1.5        no  \n",
            "4              7.7          4.3               1.2        no  \n",
            "Accuracy: 0.5641025641025641 (or 56.4 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 evaluation\n",
        "Example text: The following code cell evaluates a Decision Tree model. The resulting [insert name of performance metric] is ##.\n",
        "\n",
        "**Note that completing these first two sections (\"Dataset preparation\" and \"Model 1 evaluation\") would be enough for a pass mark :)**"
      ],
      "metadata": {
        "id": "sL8UeAHZnqmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 1:\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_examples)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy * 100, 1), \"%)\")"
      ],
      "metadata": {
        "id": "iKxJ4Ykkn55u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8701da-1029-4308-f637-c4052f0c2f92"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5641025641025641 (or 56.4 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16f8fb55"
      },
      "source": [
        "## Model 1 evaluation\n",
        "The following code cell evaluates a Decision Tree model. The resulting accuracy is 56.4 %.\n",
        "\n",
        "**Note that completing these first two sections (\"Dataset preparation\" and \"Model 1 evaluation\") would be enough for a pass mark :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 evaluation\n",
        "Example text: The following code cell evaluates a k-Nearest Neighbours model. The resulting [insert name of performance metric] is ##."
      ],
      "metadata": {
        "id": "jODZIy0goBq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 2:\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "CGySKGRIoTo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 evaluation\n",
        "Example text: The following code cell evaluates a Naive Bayes model. The resulting [insert name of performance metric] is ##."
      ],
      "metadata": {
        "id": "3QI7cdD7FwzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model 3:\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "Shgqb0TFFzFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model # evaluation\n",
        "**Keep repeating the basic text cell + code cell structure for every model you evaluate.**\n",
        "\n",
        "Example text: The following code cell evaluates a ... model. The resulting [insert name of performance metric] is ##.\n"
      ],
      "metadata": {
        "id": "NZzuujKKoV2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model N:\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "l2i9f11jpCzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aiming for higher marks\n",
        "\n",
        "Broadly speaking, for higher marks you need to: evaluate extra models; evaluate the impact of relevant hyperparameters; evaluate ensembles of relevant models; take steps to improve your recipe; justify those recipe changes in the relevant text cells. See the assignment specification for full details.\n",
        "\n",
        "As you make improvements to your code and text cells, it's no problem temporarily to leave old code/text cells in the notebook (e.g., for safety, cross-checking). But by the time you come to submit your work, try to remove your old work and leave us just with your final approach for marking.\n",
        "\n",
        "Task 1 code that meets the requirements of the higher marking bands also meets the requirements of the lower ones. So we only need to see where your investigation ended up, and not all the intermediate steps you took to get it there.\n",
        "\n",
        "Any questions, don't hesitate to ask."
      ],
      "metadata": {
        "id": "q3amlY7B5Zlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "sy8Ti3ijvwBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Colleague's claim: \"*Instead of non-medical staff trying to extract relevant measurements from x-rays manually, we can classify the raw x-ray image data directly; it should be possible to get improved performance, and save on staff time, without any downsides*\"\n",
        "\n"
      ],
      "metadata": {
        "id": "8yI5o2hNDTIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic structure\n",
        "\n",
        "There is pretty much complete freedom in how you structure your analysis for task 2. Please just use plenty of section headings to keep your approach clear. Switching on the table of contents (View->Table of contents) should give us a good overview of how you have structured your analysis.\n",
        "\n",
        "Beyond that, it's a case of adding as many text and code cells as you want/need in order to complete your analysis.\n",
        "\n",
        "Notice that there is more than one aspect to the claim. Thinking about each aspect in turn (and potential links between them) may help you to structure your work on this task."
      ],
      "metadata": {
        "id": "z96hNTgpvz7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: ...\n",
        "Analyse (some aspect of) the claim using text cells (which can include images, equations, tables, etc.)..."
      ],
      "metadata": {
        "id": "3lOHTEV51N8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# and perhaps using code cells / experiments as well\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "PrONBSEL1oNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure you discuss any code outputs/experimental findings, and make clear their relevance to the analysis."
      ],
      "metadata": {
        "id": "sNPB9_6425xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: ...\n",
        "Analyse (some aspect of) the claim using text cells..."
      ],
      "metadata": {
        "id": "D9IoZ3zq1SIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# and perhaps using code cells / experiments as well\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "osXIzPjm1_lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "AY5cHZVu3jTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ..."
      ],
      "metadata": {
        "id": "eOup1q2M3kMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "nxW0yf2r3jgS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: ...\n",
        "Analyse (some aspect of) the claim using text cells..."
      ],
      "metadata": {
        "id": "m6NstVMy1SQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# and perhaps using code cells / experiments as well\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "cFTpvGoP1__5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "FPT_bve84pml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section #: ...\n",
        "Use as many sections as you need."
      ],
      "metadata": {
        "id": "vYweybSW2L_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will need to cite and reference all other sources of information, ideas or materials as part of this work, and so you will have citations within the body of the notebook, and a final \"References\" text cell at the end. One has been left in below as a reminder. It includes a link to the MMU library guidance for using Cite Them Right Harvard."
      ],
      "metadata": {
        "id": "3sl7yQzXAujm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "This is where you would conclude your work on both tasks.\n",
        "\n",
        "You should be able to get some text in place for task 1 quite quickly:\n",
        "\n",
        "Example text for task 1: This investigation used a shuffled 60/40 train/test holdout split to evaluate the following models: [insert list of models]. It found that the ... model gave the strongest performance with a [insert name of performance metric] of ##.\n",
        "\n",
        "You could then leave this section alone for a while as you work on adding more models to your investigation and improving your recipe. But eventually you need to come back and update it to reflect your final findings.\n",
        "\n",
        "For task 2 you need to refer back to your earlier analysis work in order to make final judgements about each aspect of the claim. On balance, is your colleague right in what they are saying, or not? And finally, overall, do you think the claim should be pursued, versus the manual measurement process you investigated in task 1?\n",
        "\n",
        "**If you're not able to make/conclude an analysis for task 2 you can still get a good mark for a properly concluded task 1 investigation**"
      ],
      "metadata": {
        "id": "crrEcjuRSat8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "All other sources you draw on need properly citing and referencing using Cite Them Right Harvard. This means adding citations at the relevant points in the notebook (where you use the source), as well as the corresponding references here. The MMU library guidance for Cite Them Right Harvard is available [here](https://www.mmu.ac.uk/library/referencing-and-study-support/referencing/cite-them-right-harvard)."
      ],
      "metadata": {
        "id": "IimICHFFTFZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission\n",
        "\n",
        "Once you're ready to submit, you need to compress the whole of your 1CWK100 folder as a .zip file (no other compression formats), and upload it to Moodle. There are several ways to do this, but the instructions below offer a simple step-by-step guide:\n",
        "\n",
        "*    **Make sure the output from any code cells you have added is showing (you can select 'Runtime' -> 'Run all' if you need to)**\n",
        "*    Save your notebook (select 'File' -> 'Save')\n",
        "*    Find your /1CWK100/ folder via the Google Drive web interface ([https://drive.google.com/](https://https://drive.google.com/))\n",
        "*    Right-click on the /1CWK100/ folder, and select 'Download'. This will cause the folder to be compressed into a .zip file and then downloaded to your local machine.\n",
        "*    Upload the resulting .zip file to the 1CWK100 submission point on Moodle.\n",
        "*    (If the .zip is too large for Moodle, upload it to your University OneDrive instead, and upload a link to that copy on Moodle)\n",
        "\n",
        "**We recommend testing these steps, and asking any questions you might have, well before the final deadline.**"
      ],
      "metadata": {
        "id": "XDWLeO4Z2-F8"
      }
    }
  ]
}