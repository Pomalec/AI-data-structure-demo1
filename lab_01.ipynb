{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pomalec/AI-data-structure-demo1/blob/main/lab_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome\n",
        "\n",
        "Welcome to the first set of lab tasks. If you've managed to open this file up in Colab then you've hopefully already worked through the \"Preparatory Tasks\" on Moodle.\n",
        "\n",
        "You should already know about:\n",
        "\n",
        "*   Our use of Google Drive and a root-level folder called /AI/\n",
        "*   How to download, unzip, and upload the new lab tasks each week\n",
        "*   How to run the notebooks in Google Colab, and the purpose of the first 3 code cells\n",
        "\n",
        "Recall that the next three code cells will be found at the start of every notebook and you can just run them! Work through them in order, hovering over them with your mouse and clicking the little \"play\" button that appears."
      ],
      "metadata": {
        "id": "HOFWCXJCRVP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O48T-zQhQ3ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4d3290-ea29-4fcb-ccf6-a2fbda45ba3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change current working directory\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/')"
      ],
      "metadata": {
        "id": "AxBRFxJTRCZI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check we can see the data\n",
        "print(os.path.isfile('iris.csv'))"
      ],
      "metadata": {
        "id": "0514PsCZREBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8de0097-4d80-4106-85ff-479c3bd9aa3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative AI use in labs\n"
      ],
      "metadata": {
        "id": "an6YZAWDvH4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your favourite large language model (YFLLM)\n",
        "\n",
        "Remember that as you work it's fine (and expected!) that you be talking to your favourite large language model (YFLLM) - e.g., [Microsoft Copilot](https://https://copilot.microsoft.com/). But try to centre your own learning, rather than just asking it to generate answers for you to copy/paste. There's further guidance on how to make the best use of generative AI tools on this module in the \"[How to study](https://moodle.mmu.ac.uk/mod/page/view.php?id=4935302)\" page on Moodle.\n",
        "\n",
        "The solutions to the lab tasks are available on Moodle if you want to look at them."
      ],
      "metadata": {
        "id": "BwFiKNlWN4V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini for Colab\n",
        "\n",
        "Google's Gemini LLM is now embedded into Colab's interface and will suggest context-aware autocompletions for your code, by default. Auto-completion suggestions can sometimes be a useful time-saver, but they can also be distracting and stop you from thinking and learning. Consider turning Colab’s code completion suggestions off if you find this is happening (Tools->Settings->Editor->see checkbox options)."
      ],
      "metadata": {
        "id": "2GU_19TCuHZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The iris.csv data\n",
        "\n",
        "Recall the iris.csv data from the lecture materials. It contains 4 measurements taken from 3 different species of iris. The overall challenge is to try and predict the species of iris from the measurements: a classification problem. It's not particularly exciting data, but it's good for practicing and learning about supervised learning techniques with.\n",
        "\n",
        "You should still have a copy of the iris.csv file on your local machine following unzipping (probably in your Downloads/ folder). Open it up in Excel and have a look at the data.\n",
        "\n",
        "In a moment we'll introduce some Python code that applies the basic machine learning recipe from the lecture to the iris.csv file, but before we do, we need to introduce a little bit more supervised learning terminology.\n",
        "\n",
        "Have a look over the terminology document on Moodle ([direct link](https://moodle.mmu.ac.uk/pluginfile.php/8206181/mod_resource/content/5/1-AI-2526-terminology.pdf)) and then answer the questions about the iris.csv file, below:\n",
        "\n",
        "*Double click to type your answers in:*\n",
        "\n",
        "1.   How many **observations** are there? **type your answer here**\n",
        "2.   How many **features** are there? **type your answer here**\n",
        "3.   What is the name of the **target feature**? **type your answer here**\n",
        "4.   How many **predictive features** are there? **type your answer here**\n",
        "5.   What is the first **predictive feature value** in the first **observation**? **type your answer here**\n",
        "6.   Has the data been sorted in any way? **type your answer here**"
      ],
      "metadata": {
        "id": "146QIlRGYqz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic supervised learning recipe\n",
        "\n",
        "The code below implements the basic supervised learning recipe (steps 1-3 only) discussed in the lecture materials using Python and the [Scikit-learn](https://scikit-learn.org/stable/) machine learning package.\n",
        "\n",
        "The code trains and evaluates a model called a decision tree classifier. We won't worry about how the model works yet (more on that next week), just give the code a run and see what accuracy it produces.\n",
        "\n",
        "*   How accurate was the Decision Tree model? **type your answer here**"
      ],
      "metadata": {
        "id": "2ygXrlEYUp_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the packages we need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# <comment missing>\n",
        "observations = pd.read_csv('iris.csv')\n",
        "\n",
        "# <comment missing>\n",
        "target_feature = 'species'\n",
        "\n",
        "# <comment missing>\n",
        "examples = observations.drop(columns=target_feature).to_numpy()\n",
        "labels = observations[target_feature].to_numpy()\n",
        "\n",
        "# <comment missing>\n",
        "train_examples, test_examples, train_labels, test_labels = train_test_split(\n",
        "    examples,\n",
        "    labels,\n",
        "    test_size=0.4,\n",
        "    random_state=99,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# <comment missing>\n",
        "model = DecisionTreeClassifier(random_state=99)\n",
        "\n",
        "# <comment missing>\n",
        "model.fit(train_examples, train_labels)\n",
        "\n",
        "# <comment missing>\n",
        "predictions = model.predict(test_examples)\n",
        "\n",
        "# <comment missing>\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy, \"(or\", round(accuracy * 100, 1), \"%)\")"
      ],
      "metadata": {
        "id": "6clQWD_bVeFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4c0833-cb79-4236-91c1-50013d4b77d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95 (or 95.0 %)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now see if you can copy and paste the comments below to the right places in the code:\n",
        "\n",
        "```\n",
        "# Fit the model to our training data\n",
        "# Split into examples and labels\n",
        "# Load all the observations from file\n",
        "# Use the model to generate predictions for our testing examples\n",
        "# Set the name of the target feature\n",
        "# Calculate the model's accuracy - the fraction of predictions that were correct\n",
        "# Create a decision tree classifier model object\n",
        "# Shuffle and split into training data (60%) and testing data (40%)\n",
        "```\n",
        "\n",
        "**Tip**: adding some `print()` statements might help you to get sure about what's happening on each line. For example, `print(test_examples)` to see what's in the `test_examples` variable.\n",
        "\n",
        "**Tip**: note the first comment has been left in. The list of package imports can be really offputting when you're new to Python. You're not expected to remember them or know them off by heart - almost everyone just looks them up based on the packages they've found they want to use (or their IDE might even autocomplete them). So don't worry about them and just skip past them when you're reading new code listings."
      ],
      "metadata": {
        "id": "p5n0emkOq3JM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Structures\n",
        "\n",
        "From a Python/programming perspective, probably the most interesting thing about the code is the way that we store the data. Let's spend some time looking at the options, and seeing which of them are used, and where, in our basic recipe code."
      ],
      "metadata": {
        "id": "3gNMjyv3dKnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python lists\n",
        "\n",
        "Python has built-in ‘lists’ which you can use to store ordered collections of items. For example:"
      ],
      "metadata": {
        "id": "WWnfASAn6Pf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 3]\n",
        "print(a)\n",
        "print(type(a))"
      ],
      "metadata": {
        "id": "SwNPyYpp5pCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22cbbd9-a310-488a-8b27-9b9c8e2c82b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tip**: Python's `type()` function is really useful for finding out what data type your variables belong to - it's a good one to add to debug.\n",
        "\n",
        "Lists are really flexible, and handy for little storage jobs while you're coding. For example, you can store a mixture of different data types side by side:"
      ],
      "metadata": {
        "id": "fNxlUQ285xOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = [22, 'Dave', 4.6]\n",
        "print(b)"
      ],
      "metadata": {
        "id": "cpDIVK3q5yQp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0610eec7-5764-4314-f175-2573d9135cc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 'Dave', 4.6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can update list entries and resize lists, easily:"
      ],
      "metadata": {
        "id": "rRu2xvyc52vI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b[1] = 'Brian'\n",
        "print(b)\n",
        "b.append(99)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "XdW2gwir53TR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb53308-5161-4ebe-b06d-2029118c1429"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 'Brian', 4.6]\n",
            "[22, 'Brian', 4.6, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can 'slice' lists using the following basic notation:\n",
        "\n",
        "```\n",
        "list[start:end:step]\n",
        "```\n",
        "Where\n",
        "*   `start` = The index where the slice starts (inclusive) [defaults to 0 if omitted]\n",
        "*   `end` = The index where the slice ends (exclusive) [defaults to end of the list if omitted]\n",
        "*   `step` = The interval between elements in the slice. [defaults to 1 if omitted]\n",
        "\n",
        "For example:"
      ],
      "metadata": {
        "id": "VhkqAE5j7S6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(b[2:4:1])\n",
        "print(b[2:]) # use defaults via omission"
      ],
      "metadata": {
        "id": "qUp1ZaMC7zkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd6f2fd-a336-4631-ac75-7984963a767d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.6, 99]\n",
            "[4.6, 99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can even store other lists inside your lists and get something similar to the sorts of 2D array structures you will have worked with in other languages:"
      ],
      "metadata": {
        "id": "BO-eS8gH56d2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] # a list of lists\n",
        "print(c[1][1]) # access a single value"
      ],
      "metadata": {
        "id": "HhTp7Hy75684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb76c3fa-bc34-480f-832e-f68321bb8ddd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, lists aren't really arrays (usually a fixed-size data structure containing a single data type) and the cost of their flexibility is that they are _slow_.\n",
        "\n",
        "So, interestingly, we don't actually use any Python lists in our original code listing. They will sometimes come in handy as a quick/easy way to store data, but we'll typically use another option."
      ],
      "metadata": {
        "id": "eSxDmB6n59Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy arrays\n",
        "\n",
        "In practice, almost all array-type operations in Python are performed using the [NumPy](https://numpy.org/doc/stable/) package. NumPy implements an `ndarray` object that gives us a fast way to handle arrays that contain data of a single data type.\n",
        "\n",
        "You can create a NumPy array from Python list, for example:\n",
        "\n"
      ],
      "metadata": {
        "id": "Yg61JuFy3dt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2,5,3])\n",
        "print(type(a))\n",
        "print(a.shape)"
      ],
      "metadata": {
        "id": "up2WGEfQ6Apw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f6094-de4a-4724-c7d6-5446284cf115"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tip**: it's slightly confusing that you make `ndarray` objects with a call to a function called `array()` - it's just a quirk of the package\n",
        "\n",
        "**Tip**: NumPy arrays have a `.shape` property that shows their shape (or the number/extent of their dimensions) - it's another really useful thing to print out in your debug.\n",
        "\n",
        "Just remember now that the array can't change size (though there are NumPy helper functions to help you make differently sized _copies_ of arrays) and it can't contain mixtures of data types.\n",
        "\n",
        "One of the nicest things about NumPy arrays, once you've made them, is that the 'slicing' syntax we saw with simple Python lists, still works:"
      ],
      "metadata": {
        "id": "vqmCSHLa_aQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(a[0:3])"
      ],
      "metadata": {
        "id": "JezXU80jx0lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b894c3-2a34-4132-c7c9-8c056c899322"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slicing can be also applied across multiple dimensions of a NumPy array simultaneously. For example, here we use slicing to access values from a 2D array with what is some very compact, and hopefully intuitive, notation:"
      ],
      "metadata": {
        "id": "5u7_-WB_x0uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "print(c.shape)\n",
        "\n",
        "print(c[2,2]) # print one element - notice only one pair of square braces, versus lists\n",
        "\n",
        "print(c[0:3:1,2]) # print contents of right-hand column\n",
        "\n",
        "print(c[::,2]) # print contents of right-hand column (using defaults via omission)\n",
        "print(c[:,2]) # print contents of right-hand column (you can actually drop the second colon, too)\n",
        "\n",
        "print(c[0,:]) # print contents of first row\n",
        "\n",
        "print(c[0::2,0::2]) # print only even rows/columns"
      ],
      "metadata": {
        "id": "wQDsjHpG-QWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a93891-2dfe-49fc-9813-39f8e2cc64d7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n",
            "9\n",
            "[3 6 9]\n",
            "[3 6 9]\n",
            "[3 6 9]\n",
            "[1 2 3]\n",
            "[[1 3]\n",
            " [7 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is really useful notation for us on this module, and we'll use it quite a bit.\n",
        "\n",
        "Starting off with the `examples` and `labels` variables, almost all the variables in our original code listing are NumPy arrays. But we don't initialise the `examples` and `labels` variables from Python lists, so how are they made?"
      ],
      "metadata": {
        "id": "M3XkKJPxCjJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pandas DataFrames\n",
        "\n",
        "Any data we might want to load up on this module is likely to contain a mixture of data types (for example, numbers and strings). Rather than reverting to using Python lists to store them side-by-side, we use another nice package called [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html), which implements a `DataFrame` object capable of storing mixed data types in a 2D tabular structure.\n",
        "\n",
        "DataFrames are handy for loading our data up, and also particularly handy if you need to take extra steps to clean data (something we'll return to look at in future weeks). So the initial loading of our data is done via a Pandas DataFrame:"
      ],
      "metadata": {
        "id": "il4k91D8yw6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "observations = pd.read_csv('iris.csv')\n",
        "print(type(observations))\n",
        "print(observations.shape) # DataFrames also have a .shape property (like NumPy arrays)"
      ],
      "metadata": {
        "id": "tRCULby0HIk-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff832a91-89d5-41cb-bcd0-81aab2a7a3fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "(150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we print the resulting DataFrame object, you can see that the column titles in the .csv file have actually been integrated into the data structure itself:"
      ],
      "metadata": {
        "id": "xPLbaq3FI9RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(observations)"
      ],
      "metadata": {
        "id": "tNs90-ZdJHQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec04c83e-7506-4e1a-c6e0-03f5dca91011"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width    species\n",
            "0             5.1          3.5           1.4          0.2     setosa\n",
            "1             4.9          3.0           1.4          0.2     setosa\n",
            "2             4.7          3.2           1.3          0.2     setosa\n",
            "3             4.6          3.1           1.5          0.2     setosa\n",
            "4             5.0          3.6           1.4          0.2     setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "145           6.7          3.0           5.2          2.3  virginica\n",
            "146           6.3          2.5           5.0          1.9  virginica\n",
            "147           6.5          3.0           5.2          2.0  virginica\n",
            "148           6.2          3.4           5.4          2.3  virginica\n",
            "149           5.9          3.0           5.1          1.8  virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use them to index the DataFrame. For example, the following line prints the column of data holding sepal_width values, only:"
      ],
      "metadata": {
        "id": "MtM_8emUJJG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(observations['sepal_width'])"
      ],
      "metadata": {
        "id": "G3uza6a1JU2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b0e43e-33e1-44bd-b9a0-dabc8d43d379"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0      3.5\n",
            "1      3.0\n",
            "2      3.2\n",
            "3      3.1\n",
            "4      3.6\n",
            "      ... \n",
            "145    3.0\n",
            "146    2.5\n",
            "147    3.0\n",
            "148    3.4\n",
            "149    3.0\n",
            "Name: sepal_width, Length: 150, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrames are powerful objects with lots of functionality via a range of different methods, but for now we don't really need this power, and we'd prefer the raw speed of NumPy arrays.\n",
        "\n",
        "At the start of our original code listing, we move pretty quickly to separate the different data types in our classification problem using the DataFrame's `.drop()` method (to remove a column), and set up our `examples` and `labels` variables as NumPy arrays using the DataFrame's `.to_numpy()` method:"
      ],
      "metadata": {
        "id": "HZe9t4QtHUvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = observations.drop(columns='species').to_numpy()\n",
        "labels = observations['species'].to_numpy()\n",
        "print(type(examples))\n",
        "print(examples.shape)\n",
        "print(type(labels))\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "bSUeXxS-H8wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ab4041-f9b9-48b2-c3ab-287614405e52"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(150, 4)\n",
            "<class 'numpy.ndarray'>\n",
            "(150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we really only have one DataFrame in our code listing: `observations` right at the start. But DataFrames are still very useful objects that we'll come back to use when we look more at data cleaning in future."
      ],
      "metadata": {
        "id": "76oMgR6eLMnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictive features\n",
        "\n",
        "One thing we lose when we convert from DataFrames to NumPy arrays, is the record of the predictive features that lived in the DataFrame. This doesn't matter to any of the models we'll train - they don't care what names we assigned to different features - but the names can occasionally be useful to us.\n",
        "\n",
        "Looking them up in the original .csv file is one option - the columns stay in the same order inside our NumPy arrays. But the code below shows how to grab the predictive features from the original `observations` DataFrame, as a NumPy array, should you need them:"
      ],
      "metadata": {
        "id": "48j5xxNFp-1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab a record of the predictive features\n",
        "predictive_features = observations.drop(columns=target_feature).columns.to_numpy()\n",
        "print(predictive_features)"
      ],
      "metadata": {
        "id": "nLWKbSRvquH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7229c6d3-a497-4c6e-e582-37c11aa54ee8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sepal_length' 'sepal_width' 'petal_length' 'petal_width']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scikit-learn behaviour\n",
        "\n",
        "The Scikit-learn classes and functions we use in the original code listing are actually flexible about what format they accept data in. They will process: Python lists, NumPy arrays, or Pandas DataFrames. Much of Scikit-learn's functionality is similarly flexible.\n",
        "\n",
        "However, the package works predominantly with NumPy arrays behind the scenes, for their speed and efficiency, and there are some cases where NumPy arrays are passed back from functions/methods regardless of what you pass in (which can lead to confusion/problems for the caller).\n",
        "\n",
        "As a general rule, we will aim to pass Scikit-learn NumPy arrays to keep things simple, fast and efficient."
      ],
      "metadata": {
        "id": "iZrllA05LdSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interacting with examples and labels\n",
        "\n",
        "The code below sets up the original `examples` and `labels` variables again. Attempt the following tasks by adding code at the end of the listing:\n",
        "\n",
        "1.   Print the 'sepal_width' feature values for all examples\n",
        "2.   Print the 'sepal_width' and 'sepal_length' feature values for all examples\n",
        "3.   Print all the feature values for the 50th example\n",
        "4.   Print the petal_length feature values for the first 10 examples\n",
        "5.   Set the first example to have the new feature values: 2.1, 3.2, 4.3, 5.4\n",
        "6.   Set the first label to have the new feature value: 'virginica'\n",
        "7.   Print the unique labels (hint: find a NumPy method to help you)\n",
        "8.   Set all the examples with 'sepal_length' feature values that are less than 5.0 equal to 1.0 (hint: look up conditional indexing for NumPy arrays)"
      ],
      "metadata": {
        "id": "7SbKLchfCcQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "observations = pd.read_csv('iris.csv')\n",
        "\n",
        "examples = observations.drop(columns='species').to_numpy()\n",
        "labels = observations['species'].to_numpy()\n",
        "\n",
        "# Add your code on the lines below\n",
        "\n"
      ],
      "metadata": {
        "id": "pYYnfySFdV3d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Print the 'sepal_width' feature values for all examples\n",
        "print(labels)\n",
        "print(examples[:, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWf7kkEpJLmM",
        "outputId": "e715a00c-87b2-4ae3-8689-ea059596f042"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica']\n",
            "[3.5 3.  3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 3.7 3.4 3.  3.  4.  4.4 3.9 3.5\n",
            " 3.8 3.8 3.4 3.7 3.6 3.3 3.4 3.  3.4 3.5 3.4 3.2 3.1 3.4 4.1 4.2 3.1 3.2\n",
            " 3.5 3.6 3.  3.4 3.5 2.3 3.2 3.5 3.8 3.  3.8 3.2 3.7 3.3 3.2 3.2 3.1 2.3\n",
            " 2.8 2.8 3.3 2.4 2.9 2.7 2.  3.  2.2 2.9 2.9 3.1 3.  2.7 2.2 2.5 3.2 2.8\n",
            " 2.5 2.8 2.9 3.  2.8 3.  2.9 2.6 2.4 2.4 2.7 2.7 3.  3.4 3.1 2.3 3.  2.5\n",
            " 2.6 3.  2.6 2.3 2.7 3.  2.9 2.9 2.5 2.8 3.3 2.7 3.  2.9 3.  3.  2.5 2.9\n",
            " 2.5 3.6 3.2 2.7 3.  2.5 2.8 3.2 3.  3.8 2.6 2.2 3.2 2.8 2.8 2.7 3.3 3.2\n",
            " 2.8 3.  2.8 3.  2.8 3.8 2.8 2.8 2.6 3.  3.4 3.1 3.  3.1 3.1 3.1 2.7 3.2\n",
            " 3.3 3.  2.5 3.  3.4 3. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1D NumPy arrays\n",
        "\n",
        "You might have noticed, particularly if looking carefully at `.shape` debug in the previous sections, that 1D NumPy arrays don't have an orientation. That may be obvious, but perhaps not.\n",
        "\n",
        "Let's play with our simple 2D NumPy array again, as an example:"
      ],
      "metadata": {
        "id": "JW4rP4ZASZBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "c = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
      ],
      "metadata": {
        "id": "41-r5_NSYT1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the example of grabbing all the values in the 2nd row as a single array. We might tend to think of that array as being horizontal - it having formerly been a row of a 2D tabular structure - and therefore as having a shape of `(1,3)` or 1 row deep and 3 columns wide. NumPy doesn't, however. It's a 1D array and, from NumPy's perspective, there is no other dimension to assign it an extent of 1 in. So, if you print out its shape property you'll see `(3,)`. That is, an extent of 3 in the first dimension, and nothing else."
      ],
      "metadata": {
        "id": "olMsq22icaKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = c[1,:]\n",
        "print(row.shape)"
      ],
      "metadata": {
        "id": "Jef6RlEjYj9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly if you think of reading all the values in a single column. The result isn't vertical - it having formerly been a column of a 2d tabular structure - and it doesn't have a shape of `(3,1)`, but rather `(3,)` again:"
      ],
      "metadata": {
        "id": "IH3EfwYNcvcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column = c[:,1]\n",
        "print(column.shape)"
      ],
      "metadata": {
        "id": "NfC52DDec5_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This can matter in some circumstances on this module. For example, if you want to pass a single testing example to a model in order to generate a prediction. (Or if you want to treat 1D NumPy arrays as row or column vectors and multiply them by matrices for the extension tasks.)\n",
        "\n",
        "It's useful to keep in mind that 1D NumPy arrays don't actually have an orientation, and also that there is syntax for making sure they do.\n",
        "\n",
        "If you want to get back horizontal or vertical 2D arrays (with a single row/column, respectively), then you must make a slice that starts and ends on the same row/column index, as follows:"
      ],
      "metadata": {
        "id": "2NdsV6XKdAbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = c[1:2,:]\n",
        "column = c[:,1:2]\n",
        "print(row.shape)\n",
        "print(column.shape)"
      ],
      "metadata": {
        "id": "Q185sr5LY1-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tip**: remember that the number after the first colon is exclusive (i.e., it's the index of the element you want to stop just _before_); the number before the first colon is inclusive (it's the index you want to start from).\n",
        "\n",
        "Another solution is to use NumPy's `.atleast_2d()` method, which does pretty much what it sounds like it does, and can be handy sometimes. However, it turns everything into a horizontal array by default."
      ],
      "metadata": {
        "id": "GC3Uq7GWdySj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row = np.atleast_2d(c[1,:])\n",
        "column = np.atleast_2d(c[:,1])\n",
        "print(row.shape)\n",
        "print(column.shape)"
      ],
      "metadata": {
        "id": "cVN2ZgfbYkk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation\n",
        "\n",
        "We'll work with the Python standard library, NumPy, Pandas and Scikit-learn lots on the module. The documentation and tutorial pages for each are really useful and worth bringing together in a single place here. Googling or talking to YFLLM is often really useful for the first steps, but the documentation pages often contain the fine details:\n",
        "\n",
        "\n",
        "\n",
        "*   Python: [tutorial/examples](https://docs.python.org/3/tutorial/index.html); [docs](https://docs.python.org/3/library/index.html)\n",
        "*   NumPy: [tutorial/examples](https://numpy.org/devdocs/user/quickstart.html); [docs](https://numpy.org/doc/stable/reference/index.html)\n",
        "*   Pandas: [tutorial/examples](https://pandas.pydata.org/docs/user_guide/10min.html); [docs](https://numpy.org/doc/stable/reference/index.html)\n",
        "*   Scikit-learn: [tutorial/examples](https://scikit-learn.org/stable/auto_examples/index.html); [docs](https://scikit-learn.org/stable/api/index.html)\n",
        "\n"
      ],
      "metadata": {
        "id": "B7O9_7NSQuZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final review\n",
        "\n",
        "Now we've looked in more depth at what's happening in the basic recipe code, give it a final review. Are you happy with each of the lines of code? Do you want to add any debug to clarify anything? We'll use this basic recipe a lot in the early weeks of the module so it's good to get comfortable with it."
      ],
      "metadata": {
        "id": "kPLjGNrtvyhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connection to 1CWK100\n",
        "\n",
        "Notice you can copy/paste the basic recipe code to produce an initial solution for the first 1CWK100 task (and get a passing mark!). You'll just need to make a couple of small modifications to the original code listing; what are they? (Work inside the 1CWK100 template - available on Moodle - if you try things out...)"
      ],
      "metadata": {
        "id": "X9forGhv5ZIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extension tasks\n",
        "\n",
        "(Extension tasks are optional. They don't map to the assessment on this module and there is no harm in skipping them. However, for people who are interested in the subject, and who have the time, the extension tasks can help you deepen your machine learning knowledge and meet the module learning objectives more fully.)\n",
        "\n",
        "Start by asking YFLLM about the syntax for defining a new Python function, and ask any follow-up questions you might have.\n",
        "\n",
        "**Possible prompt**: \"*How do I define a new function in Python?*\"\n",
        "\n",
        "**Possible follow-up**: \"*How do I return more than one value?*\"\n",
        "\n",
        "**Possible follow-up**: \"*Tell me more about tuples in Python.*\"\n",
        "\n",
        "**Possible follow-up**: \"*Tell me more about tuple unpacking in Python.*\"\n",
        "\n",
        "Can you now write a `my_train_test_split()` function that re-implements the main steps carried out by scikit-learn's `train_test_split()` function? Some suggestions for approaching the re-implementation follow below:\n",
        "\n",
        "*   You don't need to accept all the same parameters as the original function straight away - start by accepting `examples` and `labels` only and use sensible\n",
        "defaults for the other values\n",
        "*   The original function will accept `examples` and `labels` as lists, ndarrays, or DataFrames - cater only for ndarrays to begin with (add support for other options later on if you want to)\n",
        "*   For the shuffle, remember that the random sequence you use to reorder the `examples` and `labels` must be the same - individual examples and labels must still correspond after the shuffle is complete\n",
        "*   You should be able to replace the call to `train_test_split()` in the original code listing with a call to `my_train_test_split()` and see a comparable performance from the model in terms of accuracy (it won't be identical due to the randomness of the shuffle)\n",
        "*   Can you extend your function to handle lists/ndarrays/DataFrames, can you extend you function to handle other helpful parameters from the caller?\n",
        "\n",
        "Assuming you're new to Python, you'll inevitably need to Google for how to do new/small things and/or chat to YFLLM and/or search the relevant docs (e.g., NumPy). This will be a regular feature of the module, and particularly of the extension tasks."
      ],
      "metadata": {
        "id": "WPPa3Tf09nhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your code on the lines below\n",
        "\n"
      ],
      "metadata": {
        "id": "-MU4WwQUfvwp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}